{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b661ddaf-8069-4efe-b77f-c9ed6986eec0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Bronze Layer\n",
    "\n",
    "- Bronze Layer - Automated Ingestion Script\n",
    "- Reads all streaming history files from **Unity Catalog Volumes** and creates a **Delta Table** in **Bronze Layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c2f9c2d-c607-490a-8bf7-b4a6c647f0f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d69229b-9530-4604-af31-61820a5b3d12",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "71f545da-84e7-4646-90e3-8932ca20857c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from bronze_config import INGESTION_CONFIG, metadata_configs\n",
    "import json\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyOAuth\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44be0f06-39f8-42be-8c71-dcb8702a167e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Spotify API Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fa6eea54-7e89-4cce-8ef0-3edea4667138",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "cache_path = \"/Workspace/Users/pg52694@alunos.uminho.pt/spotify-data-streaming-project/.spotify_token_cache\"\n",
    "scope = \"user-read-recently-played user-read-playback-state user-read-currently-playing\"\n",
    "\n",
    "auth_manager = SpotifyOAuth(scope=scope, open_browser=False, cache_path=cache_path)\n",
    "sp = spotipy.Spotify(auth_manager=auth_manager)\n",
    "\n",
    "# --- Verifica√ß√£o de Token ---\n",
    "token_info = auth_manager.get_cached_token()\n",
    "\n",
    "if not token_info:\n",
    "    auth_url = auth_manager.get_authorize_url()\n",
    "    print(f\"\\n1. Open this link: {auth_url}\")\n",
    "    \n",
    "    response_url = input(\"2. Paste the full URL here after the redirect: \")\n",
    "    \n",
    "    # Extrai o c√≥digo da URL de forma segura\n",
    "    code = auth_manager.parse_response_code(response_url)\n",
    "    \n",
    "    try:\n",
    "        # Substitu√≠mos o get_access_token pelo fluxo recomendado\n",
    "        token_info = auth_manager.get_access_token(code, as_dict=False)\n",
    "        print(\"‚úÖ Authentication successful and token cached!\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error obtaining token: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8ec35d4-473b-487e-9eb7-b31ffad3f42c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Read from json files to write Bronze Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9844f618-c5f8-498b-9889-f0c382146877",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "recently_played_schema = StructType([\n",
    "    # Track Info\n",
    "    StructField(\"track_id\", StringType(), True),\n",
    "    StructField(\"track_name\", StringType(), True),\n",
    "    StructField(\"track_uri\", StringType(), True),\n",
    "    StructField(\"track_duration_ms\", LongType(), True),\n",
    "    StructField(\"track_popularity\", IntegerType(), True),\n",
    "    StructField(\"track_is_explicit\", BooleanType(), True),\n",
    "    StructField(\"track_number\", IntegerType(), True),\n",
    "    StructField(\"track_type\", StringType(), True),\n",
    "    StructField(\"track_disc_number\", IntegerType(), True),\n",
    "    StructField(\"track_is_local\", BooleanType(), True),\n",
    "    StructField(\"track_href\", StringType(), True),\n",
    "    StructField(\"track_external_urls_spotify\", StringType(), True),\n",
    "    StructField(\"track_external_ids_isrc\", StringType(), True),\n",
    "    StructField(\"track_available_markets\", ArrayType(StringType()), True),\n",
    "    \n",
    "    # Album Info\n",
    "    StructField(\"album_id\", StringType(), True),\n",
    "    StructField(\"album_name\", StringType(), True),\n",
    "    StructField(\"album_type\", StringType(), True),\n",
    "    StructField(\"album_uri\", StringType(), True),\n",
    "    StructField(\"album_release_date\", StringType(), True),\n",
    "    StructField(\"album_release_date_precision\", StringType(), True),\n",
    "    StructField(\"album_total_tracks\", IntegerType(), True),\n",
    "    StructField(\"album_available_markets\", ArrayType(StringType()), True),\n",
    "    StructField(\"album_external_urls_spotify\", StringType(), True),\n",
    "    StructField(\"album_href\", StringType(), True),\n",
    "    StructField(\"album_images\", ArrayType(StringType()), True),\n",
    "    StructField(\"album_restrictions\", StringType(), True),\n",
    "    \n",
    "    # Album Artists\n",
    "    StructField(\"album_artists_external_urls_spotify\", ArrayType(StringType()), True),\n",
    "    StructField(\"album_artists_href\", ArrayType(StringType()), True),\n",
    "    StructField(\"album_artists_type\", ArrayType(StringType()), True),\n",
    "    StructField(\"album_artists_uri\", ArrayType(StringType()), True),\n",
    "    StructField(\"album_artists_names\", ArrayType(StringType()), True),\n",
    "    StructField(\"album_artists_ids\", ArrayType(StringType()), True),\n",
    "    \n",
    "    # Artists Info\n",
    "    StructField(\"track_artists_external_urls_spotify\", ArrayType(StringType()), True),\n",
    "    StructField(\"track_artists_href\", ArrayType(StringType()), True),\n",
    "    StructField(\"track_artists_type\", ArrayType(StringType()), True),\n",
    "    StructField(\"track_artists_uri\", ArrayType(StringType()), True),\n",
    "    StructField(\"track_artists_names\", ArrayType(StringType()), True),\n",
    "    StructField(\"track_artists_ids\", ArrayType(StringType()), True),\n",
    "    \n",
    "    # Metadata & Context\n",
    "    StructField(\"played_at\", StringType(), True),\n",
    "    StructField(\"context_type\", StringType(), True),\n",
    "    StructField(\"context_href\", StringType(), True),\n",
    "    StructField(\"context_uri\", StringType(), True),\n",
    "    StructField(\"context_external_urls_spotify\", StringType(), True),\n",
    "    StructField(\"processed_at\", TimestampType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "202a879e-42f5-453e-a7f0-25fb9dbcefa3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def flatten_api(item_raw):\n",
    "    # Navega√ß√£o segura nos n√≠veis do JSON\n",
    "    track = item_raw.get('track') or {}\n",
    "    album = track.get('album') or {}\n",
    "    context = item_raw.get('context') or {}\n",
    "    \n",
    "    # Listas de Artistas\n",
    "    track_artists = track.get('artists') or []\n",
    "    album_artists = album.get('artists') or []\n",
    "    \n",
    "    return {\n",
    "        # --- Track Info ---\n",
    "        \"track_id\": track.get('id'),\n",
    "        \"track_name\": track.get('name'),\n",
    "        \"track_uri\": track.get('uri'),\n",
    "        \"track_is_local\": track.get('is_local'),\n",
    "        \"track_duration_ms\": track.get('duration_ms'),\n",
    "        \"track_popularity\": track.get('popularity'),\n",
    "        \"track_is_explicit\": track.get('explicit'),\n",
    "        \"track_number\": track.get('track_number'),\n",
    "        \"track_type\": track.get('type'),\n",
    "        \"track_disc_number\": track.get('disc_number'),\n",
    "        \"track_href\": track.get('href'),\n",
    "        \"track_external_urls_spotify\": track.get('external_urls', {}).get('spotify'),\n",
    "        \"track_external_ids_isrc\": track.get('external_ids', {}).get('isrc'),\n",
    "        \"track_available_markets\": track.get('available_markets', []),\n",
    "\n",
    "        # --- Album Info ---\n",
    "        \"album_id\": album.get('id'),\n",
    "        \"album_name\": album.get('name'),\n",
    "        \"album_type\": album.get('album_type'),\n",
    "        \"album_uri\": album.get('uri'),\n",
    "        \"album_release_date\": album.get('release_date'),\n",
    "        \"album_release_date_precision\": album.get('release_date_precision'),\n",
    "        \"album_total_tracks\": album.get('total_tracks'),\n",
    "        \"album_available_markets\": album.get('available_markets', {}),\n",
    "        \"album_external_urls_spotify\": album.get('external_urls', {}).get('spotify'),\n",
    "        \"album_href\": album.get('href'),\n",
    "        \"album_images\": [img.get('url') for img in album.get('images', [])],\n",
    "        \"album_restrictions\": str(album.get('restrictions')) if album.get('restrictions') else None,\n",
    "\n",
    "        # --- Album Artists (Extra√≠do do n√≥ Album) ---\n",
    "        \"album_artists_external_urls_spotify\": [a.get('external_urls', {}).get('spotify') for a in album_artists],\n",
    "        \"album_artists_href\": [a.get('href') for a in album_artists],\n",
    "        \"album_artists_type\": [a.get('type') for a in album_artists],\n",
    "        \"album_artists_uri\": [a.get('uri') for a in album_artists],\n",
    "        \"album_artists_names\": [a.get('name') for a in album_artists],\n",
    "        \"album_artists_ids\": [a.get('id') for a in album_artists],\n",
    "\n",
    "        # --- Track Artists (Extra√≠do do n√≥ Track) ---\n",
    "        \"track_artists_external_urls_spotify\": [a.get('external_urls', {}).get('spotify') for a in track_artists],\n",
    "        \"track_artists_href\": [a.get('href') for a in track_artists],\n",
    "        \"track_artists_type\": [a.get('type') for a in track_artists],\n",
    "        \"track_artists_uri\": [a.get('uri') for a in track_artists],\n",
    "        \"track_artists_names\": [a.get('name') for a in track_artists],\n",
    "        \"track_artists_ids\": [a.get('id') for a in track_artists],\n",
    "\n",
    "        # --- Metadata & Context ---\n",
    "        \"played_at\": item_raw.get('played_at'),\n",
    "        \"context_type\": context.get('type'),\n",
    "        \"context_href\": context.get('href'),\n",
    "        \"context_uri\": context.get('uri'),\n",
    "        \"context_external_urls_spotify\": context.get('external_urls', {}).get('spotify'),\n",
    "        \"processed_at\": datetime.now()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4c40d20-018b-4255-9c64-4413d240c187",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for item in INGESTION_CONFIG:\n",
    "    print(f\"Processing {item['table']}...\")\n",
    "    \n",
    "    if item[\"format\"] == \"json\":\n",
    "        df = spark.read.option(\"multiLine\", \"True\").json(item[\"path\"])\n",
    "        \n",
    "    elif item[\"format\"] == \"api_call\":\n",
    "        # Puxa os dados (a tua fun√ß√£o get_spotify_api_data j√° deve retornar results['items'])\n",
    "        raw_items = sp.current_user_recently_played(limit=50)[\"items\"]\n",
    "        \n",
    "        if raw_items:\n",
    "            # Aplica o flatten simples\n",
    "            flat_data = [flatten_api(i) for i in raw_items]\n",
    "            \n",
    "            # Cria o DataFrame com o schema nativo\n",
    "            df = spark.createDataFrame(flat_data, schema=recently_played_schema)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    # Adiciona timestamp e salva\n",
    "    df_final = df.withColumn(\"processed_at\", F.current_timestamp())\n",
    "    \n",
    "    df_final.write.format(\"delta\") \\\n",
    "            .mode(item[\"mode\"]) \\\n",
    "            .option(\"mergeSchema\", \"true\") \\\n",
    "            .saveAsTable(item[\"table\"])\n",
    "\n",
    "print(\"Bronze Tables saved with success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b7f33e0d-3daf-4b13-9fea-42f7871c3d34",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Get Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee853664-f369-4991-97a9-e32f0188b4a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_streaming_history = spark.read.table(\"workspace.bronze.spotify_streaming_history_raw\")\n",
    "df_recently_played = spark.read.table(\"workspace.bronze.spotify_recently_played_raw\")\n",
    "\n",
    "df_streaming_history_track_ids = df_streaming_history \\\n",
    "    .filter(F.col(\"spotify_track_uri\").contains(\"track\")) \\\n",
    "    .select(F.split(F.col(\"spotify_track_uri\"), \":\")[2].alias(\"id\")) \\\n",
    "    .distinct()\n",
    "\n",
    "df_recently_played_track_ids = df_recently_played \\\n",
    "    .filter(F.col(\"track_uri\").contains(\"track\")) \\\n",
    "    .select(F.split(F.col(\"track_uri\"), \":\")[2].alias(\"id\")) \\\n",
    "    .distinct()\n",
    "\n",
    "df_track_ids = df_streaming_history_track_ids.union(df_recently_played_track_ids).distinct()\n",
    "\n",
    "track_ids_list = [row.id for row in df_track_ids.collect()]\n",
    "\n",
    "print(f\"Tracks: {len(track_ids_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f3c0e4a7-67d8-4b71-8ff5-09c19ca74631",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def save_metadata_to_bronze(data_list, table_name, schema):\n",
    "    if not data_list:\n",
    "        return\n",
    "    \n",
    "    # 1. Criar DataFrame a partir de Strings JSON (evita RDDs e AssertionError)\n",
    "    json_data = [(json.dumps(item),) for item in data_list if item]\n",
    "    df_raw = spark.createDataFrame(json_data, [\"json_string\"])\n",
    "    \n",
    "    # 2. Parse com Schema fixo\n",
    "    df_parsed = df_raw.select(\n",
    "        F.from_json(F.col(\"json_string\"), schema).alias(\"data\")\n",
    "    ).select(\"data.*\")\n",
    "    \n",
    "    # 3. Adicionar metadados e gravar\n",
    "    df_final = df_parsed.withColumn(\"processed_at\", F.current_timestamp())\n",
    "    \n",
    "    df_final.write.format(\"delta\") \\\n",
    "          .mode(\"append\") \\\n",
    "          .option(\"mergeSchema\", \"true\") \\\n",
    "          .saveAsTable(table_name)\n",
    "          \n",
    "    print(f\"‚úÖ {len(data_list)} new records added to {table_name}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def save_metadata_to_bronze(data_list, table_name, schema):\n",
    "#     if not data_list:\n",
    "#         return\n",
    "    \n",
    "#     # 1. Criar DataFrame a partir de Strings JSON\n",
    "#     json_data = [(json.dumps(item),) for item in data_list if item]\n",
    "#     df_raw = spark.createDataFrame(json_data, [\"json_string\"])\n",
    "    \n",
    "#     # 2. Parse com o schema que reflete a API (Hier√°rquico)\n",
    "#     df_parsed = df_raw.select(\n",
    "#         F.from_json(F.col(\"json_string\"), schema).alias(\"data\")\n",
    "#     ).select(\"data.*\")\n",
    "    \n",
    "#     # 3. Tratamento din√¢mico baseado na tabela\n",
    "#     # Se a coluna existir como Struct, extra√≠mos o valor interno para n√£o perder dados\n",
    "    \n",
    "#     # Extrair Spotify URL para qualquer entidade\n",
    "#     if \"external_urls\" in df_parsed.columns:\n",
    "#         df_parsed = df_parsed.withColumn(\"external_urls_spotify\", F.col(\"external_urls.spotify\"))\n",
    "    \n",
    "#     # Extrair ISRC para √Ålbuns ou Tracks\n",
    "#     if \"external_ids\" in df_parsed.columns:\n",
    "#         df_parsed = df_parsed.withColumn(\"external_ids_isrc\", F.col(\"external_ids.isrc\"))\n",
    "        \n",
    "#     # Extrair Seguidores para Artistas\n",
    "#     if \"followers\" in df_parsed.columns:\n",
    "#         # Verifica se followers √© um struct antes de extrair\n",
    "#         df_parsed = df_parsed.withColumn(\"total_followers\", F.col(\"followers.total\"))\n",
    "\n",
    "#     # Extrair IDs de listas aninhadas (Casos espec√≠ficos de √Ålbuns)\n",
    "#     if \"artists\" in df_parsed.columns:\n",
    "#         # Se artistas for uma lista de objetos, extrai apenas os IDs\n",
    "#         df_parsed = df_parsed.withColumn(\"artists_ids\", F.col(\"artists.id\"))\n",
    "        \n",
    "#     if \"tracks\" in df_parsed.columns:\n",
    "#         # No caso de √°lbuns, as tracks v√™m em tracks.items\n",
    "#         df_parsed = df_parsed.withColumn(\"tracks_ids\", F.col(\"tracks.items.id\"))\n",
    "\n",
    "#     # 4. Limpeza final e Timestamp\n",
    "#     df_final = df_parsed.withColumn(\"processed_at\", F.current_timestamp())\n",
    "    \n",
    "#     # Opcional: Remover as colunas originais de Struct para manter a tabela limpa\n",
    "#     cols_to_drop = [\"external_urls\", \"external_ids\", \"followers\", \"tracks\", \"artists\"]\n",
    "#     df_final = df_final.drop(*[c for c in cols_to_drop if c in df_final.columns])\n",
    "    \n",
    "#     # 5. Grava√ß√£o em Delta\n",
    "#     df_final.write.format(\"delta\") \\\n",
    "#           .mode(\"append\") \\\n",
    "#           .option(\"mergeSchema\", \"true\") \\\n",
    "#           .saveAsTable(table_name)\n",
    "          \n",
    "#     print(f\"‚úÖ {len(data_list)} new records added to {table_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c640af35-1817-494b-bf13-03dfd9bbd23c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "track_schema = StructType([\n",
    "    StructField(\"id\", StringType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"uri\", StringType(), True),\n",
    "    StructField(\"duration_ms\", LongType(), True),\n",
    "    StructField(\"available_markets\", StringType(), True),\n",
    "    StructField(\"external_urls_spotify\", StringType(), True),\n",
    "    StructField(\"explicit\", BooleanType(), True),\n",
    "    StructField(\"href\", StringType(), True),\n",
    "    StructField(\"popularity\", IntegerType(), True),\n",
    "    StructField(\"track_number\", IntegerType(), True),\n",
    "    StructField(\"type\", StringType(), True),\n",
    "    StructField(\"external_ids_isrc\", StringType(), True),\n",
    "    StructField(\"disc_number\", IntegerType(), True),\n",
    "    StructField(\"is_local\", BooleanType(), True),\n",
    "    StructField(\"album_id\", StringType(), True),\n",
    "    StructField(\"artist_ids\", ArrayType(StringType()), True),\n",
    "    StructField(\"processed_at\", TimestampType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bacac438-8836-48e5-b402-619a0726d2b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "artist_schema = StructType([\n",
    "    StructField(\"id\", StringType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"uri\", StringType(), True),\n",
    "    StructField(\"href\", StringType(), True),\n",
    "    StructField(\"type\", StringType(), True),\n",
    "    StructField(\"genres\", ArrayType(StringType()), True),\n",
    "    StructField(\"external_urls_spotify\", StringType(), True),\n",
    "    StructField(\"popularity\", IntegerType(), True),\n",
    "    StructField(\"followers\", StructType([\n",
    "        StructField(\"total\", LongType(), True)\n",
    "    ]), True),\n",
    "    StructField(\"images\", ArrayType(StructType([\n",
    "        StructField(\"url\", StringType(), True),\n",
    "        StructField(\"height\", IntegerType(), True),\n",
    "        StructField(\"width\", IntegerType(), True)\n",
    "    ])), True),\n",
    "    StructField(\"processed_at\", TimestampType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a9cf892b-314a-45dd-ab18-6a3761c7712a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "album_schema = StructType([\n",
    "    StructField(\"id\", StringType(), True),\n",
    "    StructField(\"uri\", StringType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"album_type\", StringType(), True),\n",
    "    StructField(\"type\", StringType(), True),\n",
    "    StructField(\"href\", StringType(), True),\n",
    "    StructField(\"release_date\", StringType(), True),\n",
    "    StructField(\"release_date_precision\", StringType(), True),\n",
    "    StructField(\"total_tracks\", IntegerType(), True),\n",
    "    StructField(\"label\", StringType(), True),\n",
    "    StructField(\"popularity\", IntegerType(), True),\n",
    "    # Campos que v√™m dentro de objetos no JSON:\n",
    "    StructField(\"external_urls\", StructType([\n",
    "        StructField(\"spotify\", StringType(), True)\n",
    "    ]), True),\n",
    "    StructField(\"external_ids\", StructType([\n",
    "        StructField(\"isrc\", StringType(), True)\n",
    "    ]), True),\n",
    "    StructField(\"available_markets\", ArrayType(StringType()), True),\n",
    "    StructField(\"artists\", ArrayType(StructType([\n",
    "        StructField(\"id\", StringType(), True)\n",
    "    ])), True),\n",
    "    StructField(\"tracks\", StructType([\n",
    "        StructField(\"items\", ArrayType(StructType([\n",
    "            StructField(\"id\", StringType(), True)\n",
    "        ])), True)\n",
    "    ]), True),\n",
    "    StructField(\"copyrights\", ArrayType(StructType([\n",
    "        StructField(\"text\", StringType(), True)\n",
    "    ])), True),\n",
    "    StructField(\"images\", ArrayType(StructType([\n",
    "        StructField(\"url\", StringType(), True)\n",
    "    ])), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b2ad81b8-8d29-4ac4-bcfa-7fe00da6b0e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 1. Verificar quais tracks j√° existem para n√£o repetir chamadas √† API\n",
    "# Tenta carregar os IDs existentes\n",
    "try:\n",
    "    print(f\"Verifying the existence of {metadata_configs[\"track\"][\"table\"]}...\")\n",
    "    df_existing = spark.read.table(metadata_configs[\"track\"][\"table\"]).select(\"id\").distinct()\n",
    "    existing_ids = [row.id for row in df_existing.collect()]\n",
    "    new_track_ids = [tid for tid in track_ids_list if tid not in existing_ids]\n",
    "    print(f\"‚úÖ Table  found. Filtered {len(existing_ids)} IDs that already exist.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Table not found or error reading (treating as new). Error: {str(e)[:100]}\")\n",
    "    new_track_ids = track_ids_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "587029de-c3c5-4897-acd8-7950d2e95eff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 2. PROCESSAR APENAS OS NOVOS IDS\n",
    "all_entities_data = {\"track\": []}\n",
    "artist_ids_set = set()\n",
    "album_ids_set = set()\n",
    "\n",
    "tracks_config = metadata_configs[\"track\"]\n",
    "target_table = tracks_config[\"table\"]\n",
    "\n",
    "if new_track_ids:\n",
    "    chunk_size = tracks_config[\"chunk\"]\n",
    "    print(f\"Starting API calls for {len (new_track_ids)} new tracks...\")\n",
    "    \n",
    "    for i in range(0, len(new_track_ids), chunk_size):\n",
    "        chunk = new_track_ids[i : i + chunk_size]\n",
    "        try:\n",
    "            res = sp.tracks(chunk)\n",
    "            tracks_chunk = res[tracks_config[\"key\"]]\n",
    "            \n",
    "            for track in tracks_chunk:\n",
    "                if track:\n",
    "                    track_to_save = {\n",
    "                        \"id\": track.get(\"id\"),\n",
    "                        \"name\": track.get(\"name\"),\n",
    "                        \"uri\": track.get(\"uri\"),\n",
    "                        \"href\": track.get(\"href\"),\n",
    "                        \"type\": track.get(\"type\"),\n",
    "                        \"duration_ms\": track.get(\"duration_ms\"),\n",
    "                        \"explicit\": track.get(\"explicit\"),\n",
    "                        \"popularity\": track.get(\"popularity\"),\n",
    "                        \"track_number\": track.get(\"track_number\"),\n",
    "                        \"disc_number\": track.get(\"disc_number\"),\n",
    "                        \"is_local\": track.get(\"is_local\"),\n",
    "                        \"external_ids_isrc\": track.get(\"external_ids\", {}).get(\"isrc\"),\n",
    "                        \"external_urls_spotify\": track.get(\"external_urls\", {}).get(\"spotify\"),\n",
    "                        \"album_id\": track.get(\"album\", {}).get(\"id\"),\n",
    "                        \"artist_ids\": [artist.get(\"id\") for artist in track.get(\"artists\", [])],\n",
    "                        \"available_markets\": \", \".join(track.get(\"available_markets\", [])) \n",
    "                    }\n",
    "\n",
    "                    all_entities_data[\"track\"].append(track_to_save)\n",
    "\n",
    "                    # Mantemos os sets originais para o processo de Artistas/Albums seguinte\n",
    "                    album_ids_set.add(track[\"album\"][\"id\"])\n",
    "                    for artist in track[\"artists\"]:\n",
    "                        artist_ids_set.add(artist[\"id\"])\n",
    "        except Exception as e:\n",
    "            print(f\"Error on batch {i} of tracks: {e}\")\n",
    "\n",
    "    # 3. Gravar apenas se houver dados novos\n",
    "    if all_entities_data[\"track\"]:\n",
    "        save_metadata_to_bronze(all_entities_data[\"track\"], target_table, track_schema)\n",
    "else:\n",
    "    print(\"‚ú® All trails are already documented in the Bronze table. Nothing to do.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f9f3238-288f-4183-b55b-207721d30ff7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --- FASE 2: PROCESSAR ARTISTAS E √ÅLBUNS (BATCHES DIN√ÇMICOS) ---\n",
    "# Mapeamos as listas de IDs que descobrimos na Fase 1\n",
    "id_map = {\n",
    "    \"artist\": list(artist_ids_set),\n",
    "    \"album\": list(album_ids_set)\n",
    "}\n",
    "\n",
    "# for entity in [\"artist\", \"album\"]:\n",
    "#     conf = metadata_configs[entity]\n",
    "#     ids_to_process = id_map[entity]\n",
    "#     chunk_size = conf[\"chunk\"]\n",
    "    \n",
    "#     print(f\"Processing {len(ids_to_process)} {entity}s...\")\n",
    "    \n",
    "#     entity_results = []\n",
    "#     for i in range(0, len(ids_to_process), chunk_size):\n",
    "#         chunk = ids_to_process[i : i + chunk_size]\n",
    "#         try:\n",
    "#             api_function = sp.artists if entity == \"artist\" else sp.albums\n",
    "#             res = api_function(chunk)\n",
    "#             entity_results.extend([item for item in res[conf[\"key\"]] if item])\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error on batch {i} from {entity}: {e}\")\n",
    "    \n",
    "#     schema = artist_schema if entity == \"artist\" else album_schema\n",
    "\n",
    "#     save_metadata_to_bronze(entity_results, conf[\"table\"], schema)\n",
    "\n",
    "# print(\"\\nüöÄ Metadata pipeline finished with success!\")\n",
    "\n",
    "\n",
    "\n",
    "for entity in [\"artist\", \"album\"]:\n",
    "    conf = metadata_configs[entity]\n",
    "    ids_to_process = id_map[entity]\n",
    "    chunk_size = conf[\"chunk\"]\n",
    "    \n",
    "    print(f\"Processing {len(ids_to_process)} {entity}s...\")\n",
    "    \n",
    "    entity_results = []\n",
    "    for i in range(0, len(ids_to_process), chunk_size):\n",
    "        chunk = ids_to_process[i : i + chunk_size]\n",
    "        try:\n",
    "            api_function = sp.artists if entity == \"artist\" else sp.albums\n",
    "            res = api_function(chunk)\n",
    "            \n",
    "            # --- TRATAMENTO DOS DADOS AQUI ---\n",
    "            for item in res[conf[\"key\"]]:\n",
    "                if not item: continue\n",
    "                \n",
    "                # Criamos um dicion√°rio limpo que bate certo com o teu Schema\n",
    "                flat_item = item.copy()\n",
    "                \n",
    "                # 1. Extrair URLs do Spotify (comum a ambos)\n",
    "                flat_item[\"external_urls_spotify\"] = item.get(\"external_urls\", {}).get(\"spotify\")\n",
    "                \n",
    "                if entity == \"artist\":\n",
    "                    # Followers: Extrair apenas o total\n",
    "                    flat_item[\"followers\"] = item.get(\"followers\", {}).get(\"total\")\n",
    "                    # Genres e Popularidade j√° v√™m no formato certo\n",
    "                    \n",
    "                elif entity == \"album\":\n",
    "                    # Extrair IDs dos Artistas e das Tracks (Flattening das listas)\n",
    "                    flat_item[\"artists_ids\"] = [a.get(\"id\") for a in item.get(\"artists\", [])]\n",
    "                    flat_item[\"tracks_ids\"] = [t.get(\"id\") for t in item.get(\"tracks\", {}).get(\"items\", [])]\n",
    "                    # ISRC e Available Markets\n",
    "                    flat_item[\"external_ids_isrc\"] = item.get(\"external_ids\", {}).get(\"isrc\")\n",
    "                    flat_item[\"available_markets\"] = str(item.get(\"available_markets\", []))\n",
    "                \n",
    "                # Imagens: Pegar apenas na lista de URLs se quiseres simplificar\n",
    "                # flat_item[\"images\"] = [img.get(\"url\") for img in item.get(\"images\", [])]\n",
    "\n",
    "                entity_results.append(flat_item)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error on batch {i} from {entity}: {e}\")\n",
    "    \n",
    "    # Define o schema correto\n",
    "    current_schema = artist_schema if entity == \"artist\" else album_schema\n",
    "    \n",
    "    # Envia os dados j√° \"mastigados\" para a fun√ß√£o\n",
    "    save_metadata_to_bronze(entity_results, conf[\"table\"], current_schema)\n",
    "\n",
    "\n",
    "print(\"\\nüöÄ Metadata pipeline finished with success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ce822a7-cb0e-43ef-b1b2-e3ba11b6dcd8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Check Bronze Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b585c03-3400-41af-91e1-b3e95136611a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT *\n",
    "FROM workspace.bronze.spotify_streaming_history_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d319daa9-e21d-44a6-8141-71839b8181f8",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1769721634354}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT *\n",
    "FROM workspace.bronze.spotify_recently_played_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "28693fac-6ea1-4bed-99d2-8c5eb76f5241",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT *\n",
    "FROM workspace.bronze.spotify_tracks_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f58bb9be-723d-41b1-aa1b-4b439fae04ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT *\n",
    "FROM workspace.bronze.spotify_artists_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "233253c0-ca09-4eb0-a1b2-3615cb5650d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT *\n",
    "FROM workspace.bronze.spotify_albums_raw"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": "HIGH"
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "dependencies": [
     "-r /Workspace/Users/pg52694@alunos.uminho.pt/spotify-data-streaming-project/requirements.txt"
    ],
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7774047269263453,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "bronze",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
